{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7aced42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT_DATA_DIR/valid.csv\n",
      "BERT_DATA_DIR/train.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('BERT_DATA_DIR'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12704ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import BERT tokenization\n",
    "\n",
    "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428734ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If tokenization can't be installed, try:\n",
    "# !pip install bert-tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f79fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import tokenization\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f28c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('BERT_DATA_DIR/train.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('BERT_DATA_DIR/valid.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc3348f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34552656</td>\n",
       "      <td>Java: Repeat Task Every Random Seconds</td>\n",
       "      <td>&lt;p&gt;I'm already familiar with repeating tasks e...</td>\n",
       "      <td>&lt;java&gt;&lt;repeat&gt;</td>\n",
       "      <td>2016-01-01 00:21:59</td>\n",
       "      <td>LQ_CLOSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34553034</td>\n",
       "      <td>Why are Java Optionals immutable?</td>\n",
       "      <td>&lt;p&gt;I'd like to understand why Java 8 Optionals...</td>\n",
       "      <td>&lt;java&gt;&lt;optional&gt;</td>\n",
       "      <td>2016-01-01 02:03:20</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34553174</td>\n",
       "      <td>Text Overlay Image with Darkened Opacity React...</td>\n",
       "      <td>&lt;p&gt;I am attempting to overlay a title over an ...</td>\n",
       "      <td>&lt;javascript&gt;&lt;image&gt;&lt;overlay&gt;&lt;react-native&gt;&lt;opa...</td>\n",
       "      <td>2016-01-01 02:48:24</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34553318</td>\n",
       "      <td>Why ternary operator in swift is so picky?</td>\n",
       "      <td>&lt;p&gt;The question is very simple, but I just cou...</td>\n",
       "      <td>&lt;swift&gt;&lt;operators&gt;&lt;whitespace&gt;&lt;ternary-operato...</td>\n",
       "      <td>2016-01-01 03:30:17</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34553755</td>\n",
       "      <td>hide/show fab with scale animation</td>\n",
       "      <td>&lt;p&gt;I'm using custom floatingactionmenu. I need...</td>\n",
       "      <td>&lt;android&gt;&lt;material-design&gt;&lt;floating-action-but...</td>\n",
       "      <td>2016-01-01 05:21:48</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  34552656             Java: Repeat Task Every Random Seconds   \n",
       "1  34553034                  Why are Java Optionals immutable?   \n",
       "2  34553174  Text Overlay Image with Darkened Opacity React...   \n",
       "3  34553318         Why ternary operator in swift is so picky?   \n",
       "4  34553755                 hide/show fab with scale animation   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I'm already familiar with repeating tasks e...   \n",
       "1  <p>I'd like to understand why Java 8 Optionals...   \n",
       "2  <p>I am attempting to overlay a title over an ...   \n",
       "3  <p>The question is very simple, but I just cou...   \n",
       "4  <p>I'm using custom floatingactionmenu. I need...   \n",
       "\n",
       "                                                Tags         CreationDate  \\\n",
       "0                                     <java><repeat>  2016-01-01 00:21:59   \n",
       "1                                   <java><optional>  2016-01-01 02:03:20   \n",
       "2  <javascript><image><overlay><react-native><opa...  2016-01-01 02:48:24   \n",
       "3  <swift><operators><whitespace><ternary-operato...  2016-01-01 03:30:17   \n",
       "4  <android><material-design><floating-action-but...  2016-01-01 05:21:48   \n",
       "\n",
       "          Y  \n",
       "0  LQ_CLOSE  \n",
       "1        HQ  \n",
       "2        HQ  \n",
       "3        HQ  \n",
       "4        HQ  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7359cd9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34552974</td>\n",
       "      <td>How to get all the child records from differen...</td>\n",
       "      <td>I am having 4 different tables like \\r\\nselect...</td>\n",
       "      <td>&lt;sql&gt;&lt;sql-server&gt;</td>\n",
       "      <td>2016-01-01 01:44:52</td>\n",
       "      <td>LQ_EDIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34554721</td>\n",
       "      <td>Retrieve all except some data of the another t...</td>\n",
       "      <td>I have two table m_master and tbl_appointment\\...</td>\n",
       "      <td>&lt;php&gt;&lt;mysql&gt;&lt;sql&gt;&lt;codeigniter&gt;&lt;mysqli&gt;</td>\n",
       "      <td>2016-01-01 08:43:50</td>\n",
       "      <td>LQ_EDIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34555135</td>\n",
       "      <td>Pandas: read_html</td>\n",
       "      <td>&lt;p&gt;I'm trying to extract US states from wiki U...</td>\n",
       "      <td>&lt;python&gt;&lt;pandas&gt;</td>\n",
       "      <td>2016-01-01 09:55:22</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34555448</td>\n",
       "      <td>Reader Always gimme NULL</td>\n",
       "      <td>I'm so new to C#, I wanna make an application ...</td>\n",
       "      <td>&lt;sql-server&gt;&lt;c#-4.0&gt;</td>\n",
       "      <td>2016-01-01 10:43:45</td>\n",
       "      <td>LQ_EDIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34555752</td>\n",
       "      <td>php rearrange array elements based on condition</td>\n",
       "      <td>basically i have this array:\\r\\n\\r\\n    array(...</td>\n",
       "      <td>&lt;php&gt;</td>\n",
       "      <td>2016-01-01 11:34:09</td>\n",
       "      <td>LQ_EDIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  34552974  How to get all the child records from differen...   \n",
       "1  34554721  Retrieve all except some data of the another t...   \n",
       "2  34555135                                  Pandas: read_html   \n",
       "3  34555448                           Reader Always gimme NULL   \n",
       "4  34555752    php rearrange array elements based on condition   \n",
       "\n",
       "                                                Body  \\\n",
       "0  I am having 4 different tables like \\r\\nselect...   \n",
       "1  I have two table m_master and tbl_appointment\\...   \n",
       "2  <p>I'm trying to extract US states from wiki U...   \n",
       "3  I'm so new to C#, I wanna make an application ...   \n",
       "4  basically i have this array:\\r\\n\\r\\n    array(...   \n",
       "\n",
       "                                     Tags         CreationDate        Y  \n",
       "0                       <sql><sql-server>  2016-01-01 01:44:52  LQ_EDIT  \n",
       "1  <php><mysql><sql><codeigniter><mysqli>  2016-01-01 08:43:50  LQ_EDIT  \n",
       "2                        <python><pandas>  2016-01-01 09:55:22       HQ  \n",
       "3                    <sql-server><c#-4.0>  2016-01-01 10:43:45  LQ_EDIT  \n",
       "4                                   <php>  2016-01-01 11:34:09  LQ_EDIT  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce447efe",
   "metadata": {},
   "source": [
    "### Label Encoding of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3130b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "label = preprocessing.LabelEncoder()\n",
    "y = label.fit_transform(train_data['Y'])\n",
    "y = to_categorical(y)\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfa4fc0",
   "metadata": {},
   "source": [
    "### Build a BERT layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a287186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a BERT embedding layer by importing the BERT model from hub.KerasLayer\n",
    "# use the large uncased BERT model\n",
    "m_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n",
    "bert_layer = hub.KerasLayer(m_url, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6055de",
   "metadata": {},
   "source": [
    "### Encoding the text\n",
    "we create a BERT vocab_file in the form a numpy array. We then set the text to lowercase and finally we pass our vocab_file and do_lower_case variables to the Tokenizer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "949998c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'gfile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a64ed504e74e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvocab_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolved_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdo_lower_case\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolved_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_lower_case\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFullTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbert_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/HMC/FALL2021/CS159-NLP/cs159-final-proj/bert/tokenization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, do_lower_case)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBasicTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_lower_case\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/HMC/FALL2021/CS159-NLP/cs159-final-proj/bert/tokenization.py\u001b[0m in \u001b[0;36mload_vocab\u001b[0;34m(vocab_file)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'gfile'"
     ]
    }
   ],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "\n",
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "        \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len-len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "        \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a566e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b069ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cf215e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d37b38c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
